{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Cifar10_Image_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uVK8gCIbLmK"
      },
      "source": [
        "# Classifying images of everyday objects using a neural network\n",
        "\n",
        "The ability to try many different neural network architectures to address a problem is what makes deep learning really powerful, especially compared to shallow learning techniques like linear regression, logistic regression etc. \n",
        "\n",
        "In this notebook i will:\n",
        "\n",
        "1. Explore the CIFAR10 dataset: https://www.cs.toronto.edu/~kriz/cifar.html\n",
        "2. Set up a training pipeline to train a neural network on a GPU (you can use kaggle or colab)\n",
        "3. Experiment with different network architectures & hyperparameters\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkrV-pd0DJuw"
      },
      "source": [
        "# Import Required Libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6VawZ-IbLmV"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.utils import make_grid\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCZ4NpcXbLmZ"
      },
      "source": [
        "## Exploring the CIFAR10 dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hACowSlZbLma"
      },
      "source": [
        "dataset = CIFAR10(root='data/', download=True, transform=ToTensor())\n",
        "test_dataset = CIFAR10(root='data/', train=False, transform=ToTensor())"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIwNCP-DbLmj"
      },
      "source": [
        "### Length of dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OTm_-ULbLmk",
        "outputId": "ef1faedd-a62c-49a9-aa61-5d65286f4352"
      },
      "source": [
        "dataset_size = len(dataset)\n",
        "dataset_size"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26K6h1_FbLmm"
      },
      "source": [
        "### No of images in Test Data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNMqcobxbLms",
        "outputId": "0dd76098-ac8a-40de-ddff-96634656705a"
      },
      "source": [
        "test_dataset_size = len(test_dataset)\n",
        "test_dataset_size"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sriMP2ssbLmt"
      },
      "source": [
        "### Type of Target Classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BueMSskbLmx",
        "outputId": "47daa3a9-4bb7-4daa-bc3e-70941168b20c"
      },
      "source": [
        "classes = dataset.classes\n",
        "classes"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['airplane',\n",
              " 'automobile',\n",
              " 'bird',\n",
              " 'cat',\n",
              " 'deer',\n",
              " 'dog',\n",
              " 'frog',\n",
              " 'horse',\n",
              " 'ship',\n",
              " 'truck']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J0W4ucODbLmy",
        "outputId": "1609c2db-173f-413e-d1cd-96bd9e50acf0"
      },
      "source": [
        "num_classes = len(classes)\n",
        "num_classes"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGrcpAhlbLmz"
      },
      "source": [
        "### The shape of an image tensor from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGKj8MN7bLm0",
        "outputId": "938ec524-f19a-4cb8-bd9c-c67c7bde6905"
      },
      "source": [
        "img, label = dataset[0]\n",
        "img_shape = img.shape\n",
        "img_shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iApXHGoSbLm1"
      },
      "source": [
        "Note that this dataset consists of 3-channel color images (RGB). Let us look at a sample image from the dataset. `matplotlib` expects channels to be the last dimension of the image tensors (whereas in PyTorch they are the first dimension), so we'll the `.permute` tensor method to shift channels to the last dimension. Let's also print the label for the image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW0RnH4zbLm3"
      },
      "source": [
        "img, label = dataset[0]\n",
        "plt.imshow(img.permute((1, 2, 0)))\n",
        "print('Label (numeric):', label)\n",
        "print('Label (textual):', classes[label])"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0R4PndjubLm4"
      },
      "source": [
        "### No of Images belong to each classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34XlNLiGbLm5"
      },
      "source": [
        "di = dict()\r\n",
        "for each in dataset:\r\n",
        "  label = classes[each[1]]\r\n",
        "  if label not in di.keys():\r\n",
        "    di[label]=1\r\n",
        "  else:\r\n",
        "    di[label]+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP7NsIjOiHQA"
      },
      "source": [
        "di"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SibNDYP-bLnC"
      },
      "source": [
        "## Preparing the data for training\n",
        "\n",
        "I'll use a validation set with 5000 images (10% of the dataset). To ensure I get the same validation set each time, I'll set PyTorch's random number generator to a seed value of 43."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0eqYj4ebLnD"
      },
      "source": [
        "torch.manual_seed(43)\n",
        "val_size = 5000\n",
        "train_size = len(dataset) - val_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSQW3yn8bLnE"
      },
      "source": [
        "Let's use the `random_split` method to create the training & validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhcJ6i80bLnG"
      },
      "source": [
        "train_ds, val_ds = random_split(dataset, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PO4AVuoTbLnL"
      },
      "source": [
        "We can now create data loaders to load the data in batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S2tnJKb4bLnM"
      },
      "source": [
        "batch_size=128"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWWbUXHfbLnM"
      },
      "source": [
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
        "val_loader = DataLoader(val_ds, batch_size*2, num_workers=4, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size*2, num_workers=4, pin_memory=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVNbkk2WbLnN"
      },
      "source": [
        "Let's visualize a batch of data using the `make_grid` helper function from Torchvision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QU-BqzSbLnO"
      },
      "source": [
        "for images, _ in train_loader:\n",
        "    print('images.shape:', images.shape)\n",
        "    plt.figure(figsize=(16,8))\n",
        "    plt.axis('off')\n",
        "    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kg6UmlGgbLnX"
      },
      "source": [
        "## Base Model class & Training on GPU\n",
        "\n",
        "Let's create a base model class, which contains everything except the model architecture i.e. it wil not contain the `__init__` and `__forward__` methods. We will later extend this class to try out different architectures. In fact, we can extend this model to solve any image classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwteTIzSbLnY"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6PeK-uKbLnZ"
      },
      "source": [
        "class ImageClassificationBase(nn.Module):\n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss.detach(), 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "faEneMhwbLnb"
      },
      "source": [
        "We can also use the exact same training loop as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuP65LNLbLnf"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)\n",
        "\n",
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    history = []\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    for epoch in range(epochs):\n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSct3-H3bLni"
      },
      "source": [
        "Finally, let's also define some utilities for moving out data & labels to the GPU, if one is available."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqkv8_xZbLnk"
      },
      "source": [
        "torch.cuda.is_available()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLsjFBp9bLnu"
      },
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0cujyQXbLnw"
      },
      "source": [
        "device = get_default_device()\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmREyMY2bLn1"
      },
      "source": [
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Mi_vrlbLn3"
      },
      "source": [
        "Let us also define a couple of helper functions for plotting the losses & accuracies."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4R6vziMbLn6"
      },
      "source": [
        "def plot_losses(history):\n",
        "    losses = [x['val_loss'] for x in history]\n",
        "    plt.plot(losses, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('loss')\n",
        "    plt.title('Loss vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NVyQndxbLn7"
      },
      "source": [
        "def plot_accuracies(history):\n",
        "    accuracies = [x['val_acc'] for x in history]\n",
        "    plt.plot(accuracies, '-x')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.title('Accuracy vs. No. of epochs');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0niFvowbLn8"
      },
      "source": [
        "Let's move our data loaders to the appropriate device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLKAp6NGbLn9"
      },
      "source": [
        "train_loader = DeviceDataLoader(train_loader, device)\n",
        "val_loader = DeviceDataLoader(val_loader, device)\n",
        "test_loader = DeviceDataLoader(test_loader, device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7FP5MJSbLoH"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "We will make several attempts at training the model. Each time, try a different architecture and a different set of learning rates. Here are some ideas to try:\n",
        "- Increase or decrease the number of hidden layers\n",
        "- Increase of decrease the size of each hidden layer\n",
        "- Try different activation functions\n",
        "- Try training for different number of epochs\n",
        "- Try different learning rates in every epoch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9ZoHdMCbLoJ"
      },
      "source": [
        "input_size = 3*32*32\n",
        "hidden_size1 = 512\n",
        "hidden_size2 = 32\n",
        "output_size = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZrvdAuqpkj9"
      },
      "source": [
        "input_size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4nT4IrobLoL"
      },
      "source": [
        "class CIFAR10Model(ImageClassificationBase):\n",
        "    def __init__(self, in_size, hidden_size1,hidden_size2, out_size):\n",
        "        super().__init__()\n",
        "         # hidden layer\n",
        "        self.linear1 = nn.Linear(in_size, hidden_size1)\n",
        "        # hidden layer\n",
        "        self.linear2 = nn.Linear(hidden_size1, hidden_size2)\n",
        "        # output layer \n",
        "        self.linear3 = nn.Linear(hidden_size2,out_size)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        # Flatten images into vectors\n",
        "        out = xb.view(xb.size(0), -1)\n",
        "        # Apply layers & activation functions\n",
        "        # Get intermediate outputs using hidden layer\n",
        "        out = self.linear1(out)\n",
        "        # Apply activation function\n",
        "        out = F.relu(out)\n",
        "       # Get intermediate outputs using hidden layer\n",
        "        out = self.linear2(out)\n",
        "        # Apply activation function\n",
        "        out = F.relu(out)\n",
        "        # Get predictions using output layer\n",
        "        out = self.linear3(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVkao9EwbLoN"
      },
      "source": [
        "we can now instantiate the model, and move it the appropriate device."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XraDxQzfbLoO"
      },
      "source": [
        "model = to_device(CIFAR10Model(input_size,hidden_size1,hidden_size2,output_size), device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Skyinp1bLoQ"
      },
      "source": [
        "Before we train the model, it's a good idea to check the validation loss & accuracy with the initial set of weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6up3DnxbLoR"
      },
      "source": [
        "history = [evaluate(model, val_loader)]\n",
        "history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDBeioKhbLoS"
      },
      "source": [
        "\n",
        "Leverage the interactive nature of Jupyter to train the model in multiple phases, adjusting the no. of epochs & learning rate each time based on the result of the previous training phase."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcRm_LSUbLob"
      },
      "source": [
        "history += fit(10, 1.05, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xMwWi2dBbLoc"
      },
      "source": [
        "history += fit(50, 0.25, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dSkN8lLbLoe"
      },
      "source": [
        "history += fit(50, 0.10, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rshmV9mbLof"
      },
      "source": [
        "history += fit(10, 0.05, model, train_loader, val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLEDHY7kbLog"
      },
      "source": [
        "Plot the losses and the accuracies to check if you're starting to hit the limits of how well your model can perform on this dataset. You can train some more if you can see the scope for further improvement."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynB7VyUFbLoh"
      },
      "source": [
        "plot_losses(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvnA3PskbLoi"
      },
      "source": [
        "plot_accuracies(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNXbu3GwbLoo"
      },
      "source": [
        "Finally, evaluate the model on the test dataset report its final performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i200rm-DbLoq"
      },
      "source": [
        "evaluate(model, test_loader)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}